{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415d7727",
   "metadata": {
    "papermill": {
     "duration": 0.007735,
     "end_time": "2024-10-06T14:49:21.153892",
     "exception": false,
     "start_time": "2024-10-06T14:49:21.146157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Named Entity Recognition(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd1ef1",
   "metadata": {
    "papermill": {
     "duration": 0.006872,
     "end_time": "2024-10-06T14:49:21.168003",
     "exception": false,
     "start_time": "2024-10-06T14:49:21.161131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972341f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:49:21.183409Z",
     "iopub.status.busy": "2024-10-06T14:49:21.183035Z",
     "iopub.status.idle": "2024-10-06T14:49:22.724109Z",
     "shell.execute_reply": "2024-10-06T14:49:22.723123Z"
    },
    "papermill": {
     "duration": 1.551296,
     "end_time": "2024-10-06T14:49:22.726477",
     "exception": false,
     "start_time": "2024-10-06T14:49:21.175181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5745b6",
   "metadata": {
    "papermill": {
     "duration": 0.00724,
     "end_time": "2024-10-06T14:49:22.741499",
     "exception": false,
     "start_time": "2024-10-06T14:49:22.734259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea19e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:49:22.757133Z",
     "iopub.status.busy": "2024-10-06T14:49:22.756694Z",
     "iopub.status.idle": "2024-10-06T14:49:22.761898Z",
     "shell.execute_reply": "2024-10-06T14:49:22.761032Z"
    },
    "papermill": {
     "duration": 0.015382,
     "end_time": "2024-10-06T14:49:22.764023",
     "exception": false,
     "start_time": "2024-10-06T14:49:22.748641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loading_data(data_path):\n",
    "    \n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    data.dropna(inplace=True)\n",
    "    print(\"Number of rows : \",data.shape[0],\" and the number of columns : \",data.shape[1])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee82e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:49:22.779429Z",
     "iopub.status.busy": "2024-10-06T14:49:22.779146Z",
     "iopub.status.idle": "2024-10-06T14:49:23.241497Z",
     "shell.execute_reply": "2024-10-06T14:49:23.240536Z"
    },
    "papermill": {
     "duration": 0.473162,
     "end_time": "2024-10-06T14:49:23.244361",
     "exception": false,
     "start_time": "2024-10-06T14:49:22.771199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows :  47959  and the number of columns :  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #                                           Sentence  \\\n",
       "0  Sentence: 1  Thousands of demonstrators have marched throug...   \n",
       "1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n",
       "2  Sentence: 3  They marched from the Houses of Parliament to ...   \n",
       "3  Sentence: 4  Police put the number of marchers at 10,000 wh...   \n",
       "4  Sentence: 5  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
       "1  ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...   \n",
       "2  ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...   \n",
       "3  ['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...   \n",
       "4  ['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loading_data(\"/kaggle/input/named-entity-recognition-ner-corpus/ner.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b43e6d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:49:23.260919Z",
     "iopub.status.busy": "2024-10-06T14:49:23.260624Z",
     "iopub.status.idle": "2024-10-06T14:49:23.266206Z",
     "shell.execute_reply": "2024-10-06T14:49:23.265356Z"
    },
    "papermill": {
     "duration": 0.015864,
     "end_time": "2024-10-06T14:49:23.268031",
     "exception": false,
     "start_time": "2024-10-06T14:49:23.252167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['POS'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d21b0",
   "metadata": {
    "papermill": {
     "duration": 0.008098,
     "end_time": "2024-10-06T14:49:23.283897",
     "exception": false,
     "start_time": "2024-10-06T14:49:23.275799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fdef40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:49:23.301331Z",
     "iopub.status.busy": "2024-10-06T14:49:23.300835Z",
     "iopub.status.idle": "2024-10-06T14:49:23.306475Z",
     "shell.execute_reply": "2024-10-06T14:49:23.305592Z"
    },
    "papermill": {
     "duration": 0.016782,
     "end_time": "2024-10-06T14:49:23.308407",
     "exception": false,
     "start_time": "2024-10-06T14:49:23.291625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    for i in range(len(data)):\n",
    "        pos = ast.literal_eval(data['POS'][i])\n",
    "        tags = ast.literal_eval(data['Tag'][i])\n",
    "        data['POS'][i] = [str(word) for word in pos]\n",
    "        data['Tag'][i] = [str(word.upper()) for word in tags]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33760f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:49:23.324875Z",
     "iopub.status.busy": "2024-10-06T14:49:23.324628Z",
     "iopub.status.idle": "2024-10-06T14:50:08.666262Z",
     "shell.execute_reply": "2024-10-06T14:50:08.665279Z"
    },
    "papermill": {
     "duration": 45.359868,
     "end_time": "2024-10-06T14:50:08.675864",
     "exception": false,
     "start_time": "2024-10-06T14:49:23.315996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>[NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NNS, IN, NN, TO, DT, NN, IN...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>[NNS, VBD, DT, NN, IN, NNS, IN, CD, IN, NNS, V...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>[DT, NN, VBZ, IN, DT, NN, IN, DT, JJ, NN, IN, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #                                           Sentence  \\\n",
       "0  Sentence: 1  Thousands of demonstrators have marched throug...   \n",
       "1  Sentence: 2  Families of soldiers killed in the conflict jo...   \n",
       "2  Sentence: 3  They marched from the Houses of Parliament to ...   \n",
       "3  Sentence: 4  Police put the number of marchers at 10,000 wh...   \n",
       "4  Sentence: 5  The protest comes on the eve of the annual con...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
       "1  [NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...   \n",
       "2  [PRP, VBD, IN, DT, NNS, IN, NN, TO, DT, NN, IN...   \n",
       "3  [NNS, VBD, DT, NN, IN, NNS, IN, CD, IN, NNS, V...   \n",
       "4  [DT, NN, VBZ, IN, DT, NN, IN, DT, JJ, NN, IN, ...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  [O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...  \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef4d6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:08.693720Z",
     "iopub.status.busy": "2024-10-06T14:50:08.693404Z",
     "iopub.status.idle": "2024-10-06T14:50:08.699682Z",
     "shell.execute_reply": "2024-10-06T14:50:08.698825Z"
    },
    "papermill": {
     "duration": 0.017412,
     "end_time": "2024-10-06T14:50:08.701694",
     "exception": false,
     "start_time": "2024-10-06T14:50:08.684282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def lower_text(text: str):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_punctuation(text: str):\n",
    "    \"\"\"\n",
    "    Substitute all punctiations with space in case of\n",
    "    \"hello!nice to meet you\"\n",
    "    \n",
    "    If subs with '' -> \"hellonice to meet you\"\n",
    "    With ' ' -> \"hello nice to meet you\"\n",
    "    \"\"\"\n",
    "    text_nopunct = re.sub('[^A-Za-z0-9\\s]', '', text)\n",
    "    return text_nopunct\n",
    "\n",
    "def remove_multiple_spaces(text: str):\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text)\n",
    "    return text_no_doublespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945d2233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:08.718680Z",
     "iopub.status.busy": "2024-10-06T14:50:08.718433Z",
     "iopub.status.idle": "2024-10-06T14:50:08.724583Z",
     "shell.execute_reply": "2024-10-06T14:50:08.723645Z"
    },
    "papermill": {
     "duration": 0.017032,
     "end_time": "2024-10-06T14:50:08.726651",
     "exception": false,
     "start_time": "2024-10-06T14:50:08.709619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .\n",
      "----------\n",
      "police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .\n",
      "----------\n",
      "police put the number of marchers at 10000 while organizers claimed it was 100000 \n",
      "----------\n",
      "police put the number of marchers at 10000 while organizers claimed it was 100000 \n"
     ]
    }
   ],
   "source": [
    "sample_text = data['Sentence'][3]\n",
    "\n",
    "_lowered = lower_text(sample_text)\n",
    "_without_punct = remove_punctuation(_lowered)\n",
    "_single_spaced = remove_multiple_spaces(_without_punct)\n",
    "\n",
    "print(sample_text)\n",
    "print('-'*10)\n",
    "print(_lowered)\n",
    "print('-'*10)\n",
    "print(_without_punct)\n",
    "print('-'*10)\n",
    "print(_single_spaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35bb8bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:08.743647Z",
     "iopub.status.busy": "2024-10-06T14:50:08.743404Z",
     "iopub.status.idle": "2024-10-06T14:50:09.225266Z",
     "shell.execute_reply": "2024-10-06T14:50:09.224489Z"
    },
    "papermill": {
     "duration": 0.493007,
     "end_time": "2024-10-06T14:50:09.227616",
     "exception": false,
     "start_time": "2024-10-06T14:50:08.734609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_text(text: str) -> list[str]:\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stop_words(tokenized_text: list[str]) -> list[str]:\n",
    "    wordsFiltered = [w for w in tokenized_text if w not in stopWords]\n",
    "    return wordsFiltered\n",
    "\n",
    "def stem_words(tokenized_text: list[str]) -> list[str]:\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    output = [stemmer.lemmatize(text) for text in tokenized_text]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7011cfab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:09.245391Z",
     "iopub.status.busy": "2024-10-06T14:50:09.244829Z",
     "iopub.status.idle": "2024-10-06T14:50:09.250385Z",
     "shell.execute_reply": "2024-10-06T14:50:09.249535Z"
    },
    "papermill": {
     "duration": 0.01648,
     "end_time": "2024-10-06T14:50:09.252301",
     "exception": false,
     "start_time": "2024-10-06T14:50:09.235821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing_stage(text):\n",
    "    _lowered = lower_text(text)\n",
    "    _without_punct = remove_punctuation(_lowered)\n",
    "    _single_spaced = remove_multiple_spaces(_without_punct)\n",
    "    _tokenized = tokenize_text(_single_spaced)\n",
    "#     _without_sw = remove_stop_words(_tokenized)\n",
    "    _stemmed = stem_words(_tokenized)\n",
    "    _stemmed = ' '.join(_stemmed)\n",
    "    \n",
    "    return _stemmed\n",
    "\n",
    "def clean_text_inplace(df):\n",
    "    df['Sentence'] = df['Sentence'].apply(preprocessing_stage)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a666e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:09.269145Z",
     "iopub.status.busy": "2024-10-06T14:50:09.268848Z",
     "iopub.status.idle": "2024-10-06T14:50:30.985566Z",
     "shell.execute_reply": "2024-10-06T14:50:30.984403Z"
    },
    "papermill": {
     "duration": 21.727703,
     "end_time": "2024-10-06T14:50:30.987838",
     "exception": false,
     "start_time": "2024-10-06T14:50:09.260135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n",
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>thousand of demonstrator have marched through ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>family of soldier killed in the conflict joine...</td>\n",
       "      <td>[NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>they marched from the house of parliament to a...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NNS, IN, NN, TO, DT, NN, IN...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>police put the number of marcher at 10000 whil...</td>\n",
       "      <td>[NNS, VBD, DT, NN, IN, NNS, IN, CD, IN, NNS, V...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>the protest come on the eve of the annual conf...</td>\n",
       "      <td>[DT, NN, VBZ, IN, DT, NN, IN, DT, JJ, NN, IN, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #                                           Sentence  \\\n",
       "0  Sentence: 1  thousand of demonstrator have marched through ...   \n",
       "1  Sentence: 2  family of soldier killed in the conflict joine...   \n",
       "2  Sentence: 3  they marched from the house of parliament to a...   \n",
       "3  Sentence: 4  police put the number of marcher at 10000 whil...   \n",
       "4  Sentence: 5  the protest come on the eve of the annual conf...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
       "1  [NNS, IN, NNS, VBN, IN, DT, NN, VBD, DT, NNS, ...   \n",
       "2  [PRP, VBD, IN, DT, NNS, IN, NN, TO, DT, NN, IN...   \n",
       "3  [NNS, VBD, DT, NN, IN, NNS, IN, CD, IN, NNS, V...   \n",
       "4  [DT, NN, VBZ, IN, DT, NN, IN, DT, JJ, NN, IN, ...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  [O, O, O, O, O, O, B-GEO, O, O, O, O, O, B-GEO...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, B-GEO, I-GEO...  \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, B-GEO, O, O,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n",
    "\n",
    "\n",
    "data = clean_text_inplace(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb2afd86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:31.007505Z",
     "iopub.status.busy": "2024-10-06T14:50:31.006967Z",
     "iopub.status.idle": "2024-10-06T14:50:31.028721Z",
     "shell.execute_reply": "2024-10-06T14:50:31.027802Z"
    },
    "papermill": {
     "duration": 0.0332,
     "end_time": "2024-10-06T14:50:31.030628",
     "exception": false,
     "start_time": "2024-10-06T14:50:30.997428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38367, 9592)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = data[['Sentence','Tag']]\n",
    "\n",
    "df_train, df_test = train_test_split(df_final,test_size=0.2,random_state=42)\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32034c7",
   "metadata": {
    "papermill": {
     "duration": 0.008616,
     "end_time": "2024-10-06T14:50:31.048195",
     "exception": false,
     "start_time": "2024-10-06T14:50:31.039579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import model libraries and Make RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4947e2c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:31.066781Z",
     "iopub.status.busy": "2024-10-06T14:50:31.066527Z",
     "iopub.status.idle": "2024-10-06T14:50:42.233149Z",
     "shell.execute_reply": "2024-10-06T14:50:42.232122Z"
    },
    "papermill": {
     "duration": 11.178659,
     "end_time": "2024-10-06T14:50:42.235542",
     "exception": false,
     "start_time": "2024-10-06T14:50:31.056883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656e1385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:42.255495Z",
     "iopub.status.busy": "2024-10-06T14:50:42.254906Z",
     "iopub.status.idle": "2024-10-06T14:50:44.180682Z",
     "shell.execute_reply": "2024-10-06T14:50:44.179652Z"
    },
    "papermill": {
     "duration": 1.93807,
     "end_time": "2024-10-06T14:50:44.183250",
     "exception": false,
     "start_time": "2024-10-06T14:50:42.245180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets = list(df_train.Tag.values)\n",
    "test_targets = list(df_test.Tag.values)\n",
    "\n",
    "tokenizer = Tokenizer(lower=True,oov_token=\"UNK\")\n",
    "tokenizer.fit_on_texts(df_train['Sentence'])\n",
    "\n",
    "train_inputs = tokenizer.texts_to_sequences(df_train['Sentence'])\n",
    "test_inputs = tokenizer.texts_to_sequences(df_test['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981f68f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:44.202646Z",
     "iopub.status.busy": "2024-10-06T14:50:44.202336Z",
     "iopub.status.idle": "2024-10-06T14:50:44.207230Z",
     "shell.execute_reply": "2024-10-06T14:50:44.206322Z"
    },
    "papermill": {
     "duration": 0.016639,
     "end_time": "2024-10-06T14:50:44.209125",
     "exception": false,
     "start_time": "2024-10-06T14:50:44.192486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26047 unique tokens \n"
     ]
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx) # Vocab size\n",
    "print(\"Found %s unique tokens \"%V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c16249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:44.227963Z",
     "iopub.status.busy": "2024-10-06T14:50:44.227714Z",
     "iopub.status.idle": "2024-10-06T14:50:44.410603Z",
     "shell.execute_reply": "2024-10-06T14:50:44.409472Z"
    },
    "papermill": {
     "duration": 0.194601,
     "end_time": "2024-10-06T14:50:44.412592",
     "exception": false,
     "start_time": "2024-10-06T14:50:44.217991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique NER tags in train set:  {'B-PER', 'B-GEO', 'B-ART', 'B-ORG', 'I-ORG', 'B-GPE', 'B-NAT', 'I-ART', 'B-TIM', 'I-TIM', 'B-EVE', 'I-EVE', 'I-NAT', 'O', 'I-GEO', 'I-GPE', 'I-PER'}\n",
      "Unique NER tags in test set:  {'B-PER', 'B-GEO', 'B-ART', 'B-ORG', 'I-ORG', 'B-GPE', 'B-NAT', 'I-ART', 'B-TIM', 'I-TIM', 'I-GPE', 'B-EVE', 'I-EVE', 'O', 'I-GEO', 'I-NAT', 'I-PER'}\n"
     ]
    }
   ],
   "source": [
    "train_tags = set([val for sublist in train_targets for val in sublist])\n",
    "test_tags = set([val for sublist in test_targets for val in sublist])\n",
    "\n",
    "print(\"Unique NER tags in train set: \",train_tags)\n",
    "print(\"Unique NER tags in test set: \",test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a1a5c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:44.432499Z",
     "iopub.status.busy": "2024-10-06T14:50:44.432179Z",
     "iopub.status.idle": "2024-10-06T14:50:45.466585Z",
     "shell.execute_reply": "2024-10-06T14:50:45.465301Z"
    },
    "papermill": {
     "duration": 1.046721,
     "end_time": "2024-10-06T14:50:45.468886",
     "exception": false,
     "start_time": "2024-10-06T14:50:44.422165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(train_targets)\n",
    "train_tgt_int = tag_tokenizer.texts_to_sequences(train_targets)\n",
    "test_tgt_int = tag_tokenizer.texts_to_sequences(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4739e1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:45.488999Z",
     "iopub.status.busy": "2024-10-06T14:50:45.488682Z",
     "iopub.status.idle": "2024-10-06T14:50:45.986605Z",
     "shell.execute_reply": "2024-10-06T14:50:45.985449Z"
    },
    "papermill": {
     "duration": 0.510136,
     "end_time": "2024-10-06T14:50:45.988620",
     "exception": false,
     "start_time": "2024-10-06T14:50:45.478484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train inputs:  (38367, 77)\n",
      "Shape of test inputs:  (9592, 77)\n",
      "Shape of train targets:  (38367, 77)\n",
      "Shape of test targets:  (9592, 77)\n"
     ]
    }
   ],
   "source": [
    "# Max length\n",
    "max_length_train = max(len(sent) for sent in train_inputs)\n",
    "max_length_test = max(len(sent) for sent in test_inputs)\n",
    "max_length = max(max_length_train,max_length_test)\n",
    "\n",
    "# Pad input sequences\n",
    "train_inputs_final = pad_sequences(train_inputs, maxlen=max_length, padding=\"post\")\n",
    "print(\"Shape of train inputs: \",train_inputs_final.shape)\n",
    "\n",
    "test_inputs_final = pad_sequences(test_inputs, maxlen=max_length, padding=\"post\")\n",
    "print(\"Shape of test inputs: \",test_inputs_final.shape)\n",
    "\n",
    "train_targets_final = pad_sequences(train_tgt_int, maxlen=max_length, padding=\"post\")\n",
    "print(\"Shape of train targets: \",train_targets_final.shape)\n",
    "\n",
    "test_targets_final = pad_sequences(test_tgt_int, maxlen=max_length, padding=\"post\")\n",
    "print(\"Shape of test targets: \",test_targets_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0069b2d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:46.009015Z",
     "iopub.status.busy": "2024-10-06T14:50:46.008713Z",
     "iopub.status.idle": "2024-10-06T14:50:46.014759Z",
     "shell.execute_reply": "2024-10-06T14:50:46.013880Z"
    },
    "papermill": {
     "duration": 0.018589,
     "end_time": "2024-10-06T14:50:46.016816",
     "exception": false,
     "start_time": "2024-10-06T14:50:45.998227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes\n",
    "\n",
    "K = len(tag_tokenizer.word_index)  +1\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6c222b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:46.043410Z",
     "iopub.status.busy": "2024-10-06T14:50:46.042868Z",
     "iopub.status.idle": "2024-10-06T14:50:48.036372Z",
     "shell.execute_reply": "2024-10-06T14:50:48.035415Z"
    },
    "papermill": {
     "duration": 2.011341,
     "end_time": "2024-10-06T14:50:48.043731",
     "exception": false,
     "start_time": "2024-10-06T14:50:46.032390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 77)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 77, 128)           3334144   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 77, 128)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 77, 512)           788480    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 77, 256)           656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 77, 18)            4626      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4783634 (18.25 MB)\n",
      "Trainable params: 4783634 (18.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dropout, LSTM, TimeDistributed, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Create a MirroredStrategy for multi-GPU support\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Define the model inside the strategy scope\n",
    "with strategy.scope():\n",
    "    vector_size = 128\n",
    "\n",
    "    i = Input(shape=(max_length,))\n",
    "    x = Embedding(input_dim=V+1, output_dim=vector_size, mask_zero=True)(i)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.2))(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.2))(x)\n",
    "    x = TimeDistributed(Dense(K, activation='softmax'))(x)\n",
    "\n",
    "    model = Model(i, x)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a26ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T14:50:48.068742Z",
     "iopub.status.busy": "2024-10-06T14:50:48.068447Z",
     "iopub.status.idle": "2024-10-06T16:24:29.402943Z",
     "shell.execute_reply": "2024-10-06T16:24:29.401991Z"
    },
    "papermill": {
     "duration": 5621.349277,
     "end_time": "2024-10-06T16:24:29.405210",
     "exception": false,
     "start_time": "2024-10-06T14:50:48.055933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "Epoch 1/5\n",
      "1199/1199 [==============================] - 1156s 954ms/step - loss: 2.1441 - accuracy: 0.8415 - val_loss: 2.1397 - val_accuracy: 0.8419 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "1199/1199 [==============================] - 1124s 938ms/step - loss: 2.1394 - accuracy: 0.8421 - val_loss: 2.1397 - val_accuracy: 0.8419 - lr: 9.0000e-04\n",
      "Epoch 3/5\n",
      "1199/1199 [==============================] - 1114s 929ms/step - loss: 2.1394 - accuracy: 0.8421 - val_loss: 2.1397 - val_accuracy: 0.8419 - lr: 8.1000e-04\n",
      "Epoch 4/5\n",
      "1199/1199 [==============================] - 1112s 927ms/step - loss: 2.1394 - accuracy: 0.8421 - val_loss: 2.1397 - val_accuracy: 0.8419 - lr: 7.2900e-04\n",
      "Epoch 5/5\n",
      "1199/1199 [==============================] - 1114s 929ms/step - loss: 2.1394 - accuracy: 0.8421 - val_loss: 2.1396 - val_accuracy: 0.8419 - lr: 6.5610e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set the visible GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Change this to the GPU IDs you want to use\n",
    "\n",
    "# Limit GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Create data pipelines\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs_final, train_targets_final))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs_final, test_targets_final))\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "lr_scheduler = LearningRateScheduler(lambda epoch: 0.001 * 0.9 ** epoch)\n",
    "\n",
    "# Compile the model inside the strategy scope\n",
    "with strategy.scope():\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_dataset.batch(32),  # Adjust the batch size based on your GPU memory\n",
    "          epochs=5,\n",
    "          validation_data=test_dataset.batch(32),\n",
    "          callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Save the model\n",
    "model.save('ner_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e3d136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:24:30.361671Z",
     "iopub.status.busy": "2024-10-06T16:24:30.360815Z",
     "iopub.status.idle": "2024-10-06T16:24:30.387543Z",
     "shell.execute_reply": "2024-10-06T16:24:30.386605Z"
    },
    "papermill": {
     "duration": 0.507771,
     "end_time": "2024-10-06T16:24:30.389612",
     "exception": false,
     "start_time": "2024-10-06T16:24:29.881841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cec08b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:24:31.345300Z",
     "iopub.status.busy": "2024-10-06T16:24:31.344702Z",
     "iopub.status.idle": "2024-10-06T16:24:32.554450Z",
     "shell.execute_reply": "2024-10-06T16:24:32.553553Z"
    },
    "papermill": {
     "duration": 1.689547,
     "end_time": "2024-10-06T16:24:32.556469",
     "exception": false,
     "start_time": "2024-10-06T16:24:30.866922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.0427975e-10, 1.0000000e+00, 2.9627755e-11, ...,\n",
       "         2.7311967e-11, 5.9637273e-12, 1.5243216e-10],\n",
       "        [4.3046647e-12, 1.0000000e+00, 1.1069937e-12, ...,\n",
       "         1.1971145e-12, 1.6909662e-13, 7.2540047e-12],\n",
       "        [2.5362692e-12, 1.0000000e+00, 6.4361217e-13, ...,\n",
       "         7.1327032e-13, 9.3871010e-14, 4.4317982e-12],\n",
       "        ...,\n",
       "        [5.5214286e-02, 5.8033735e-02, 5.5201918e-02, ...,\n",
       "         5.5236496e-02, 5.5185113e-02, 5.5247698e-02],\n",
       "        [5.5214286e-02, 5.8033735e-02, 5.5201918e-02, ...,\n",
       "         5.5236496e-02, 5.5185113e-02, 5.5247698e-02],\n",
       "        [5.5214286e-02, 5.8033735e-02, 5.5201918e-02, ...,\n",
       "         5.5236496e-02, 5.5185113e-02, 5.5247698e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Polish Prime Minister Jaroslaw Kaczynski has voiced support for the deployment of 10 U.S. missile interceptors in Poland and guidance technology in the Czech Republic .\"\n",
    "sentence = preprocessing_stage(sentence)\n",
    "predictions = model.predict(pad_sequences(tokenizer.texts_to_sequences([sentence]),\n",
    "                                          maxlen=max_length,\n",
    "                                         padding=\"post\"))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06ca2c76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:24:33.571816Z",
     "iopub.status.busy": "2024-10-06T16:24:33.571430Z",
     "iopub.status.idle": "2024-10-06T16:24:33.579427Z",
     "shell.execute_reply": "2024-10-06T16:24:33.577462Z"
    },
    "papermill": {
     "duration": 0.546816,
     "end_time": "2024-10-06T16:24:33.581257",
     "exception": false,
     "start_time": "2024-10-06T16:24:33.034441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_ner = np.argmax(predictions,axis=-1)\n",
    "prediction_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb8b69df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T16:24:34.539487Z",
     "iopub.status.busy": "2024-10-06T16:24:34.539083Z",
     "iopub.status.idle": "2024-10-06T16:24:34.547819Z",
     "shell.execute_reply": "2024-10-06T16:24:34.546338Z"
    },
    "papermill": {
     "duration": 0.490054,
     "end_time": "2024-10-06T16:24:34.549799",
     "exception": false,
     "start_time": "2024-10-06T16:24:34.059745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o',\n",
       "  'o'],\n",
       " 'polish prime minister jaroslaw kaczynski ha voiced support for the deployment of 10 u missile interceptor in poland and guidance technology in the czech republic')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER_tags = [tag_tokenizer.index_word[num] for num in list(prediction_ner.flatten())]\n",
    "NER_tags[:len(tokenizer.texts_to_sequences([sentence])[0])], sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4969766",
   "metadata": {
    "papermill": {
     "duration": 0.477247,
     "end_time": "2024-10-06T16:24:35.509621",
     "exception": false,
     "start_time": "2024-10-06T16:24:35.032374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1861688,
     "sourceId": 3043695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5721.300946,
   "end_time": "2024-10-06T16:24:39.125901",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-06T14:49:17.824955",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
